{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example code to train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import VariationalAutoencoder, save_dict_pickle, load_dict_pickle, SimulationDataScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data = load_dict_pickle('20200120_simulated_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train_complete',\n",
       " 'X_val_complete',\n",
       " 'X_test_complete',\n",
       " 'Y_train_complete',\n",
       " 'Y_val_complete',\n",
       " 'Y_test_complete',\n",
       " 'X_train_um',\n",
       " 'X_val_um',\n",
       " 'X_test_um',\n",
       " 'Y_train_um',\n",
       " 'Y_val_um',\n",
       " 'Y_test_um']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(simulated_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_um = simulated_data['X_train_um']\n",
    "Y_train_um = simulated_data['Y_train_um']\n",
    "X_val_um = simulated_data['X_val_um']\n",
    "Y_val_um = simulated_data['Y_val_um']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp</th>\n",
       "      <th>shock_indexes</th>\n",
       "      <th>systolics</th>\n",
       "      <th>temperature</th>\n",
       "      <th>urine</th>\n",
       "      <th>MAP</th>\n",
       "      <th>o2_24h_max</th>\n",
       "      <th>spo2_24hr_min</th>\n",
       "      <th>pulse</th>\n",
       "      <th>AGE_AT_START_OF_ENCOUNTER</th>\n",
       "      <th>...</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>platelets</th>\n",
       "      <th>shock_index_age</th>\n",
       "      <th>anion_gap</th>\n",
       "      <th>pulse_pressure</th>\n",
       "      <th>window_num</th>\n",
       "      <th>albumin</th>\n",
       "      <th>protein_level</th>\n",
       "      <th>diastolics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49960.000000</td>\n",
       "      <td>49961.000000</td>\n",
       "      <td>49987.000000</td>\n",
       "      <td>48611.000000</td>\n",
       "      <td>37130.000000</td>\n",
       "      <td>49988.000000</td>\n",
       "      <td>49960.000000</td>\n",
       "      <td>49948.000000</td>\n",
       "      <td>49995.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32580.000000</td>\n",
       "      <td>42449.000000</td>\n",
       "      <td>43742.000000</td>\n",
       "      <td>49953.000000</td>\n",
       "      <td>43573.000000</td>\n",
       "      <td>49979.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>29704.000000</td>\n",
       "      <td>29355.000000</td>\n",
       "      <td>49986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.431267</td>\n",
       "      <td>0.714924</td>\n",
       "      <td>122.480316</td>\n",
       "      <td>36.788361</td>\n",
       "      <td>274.272186</td>\n",
       "      <td>86.151390</td>\n",
       "      <td>2.142308</td>\n",
       "      <td>92.862534</td>\n",
       "      <td>85.224884</td>\n",
       "      <td>57.526039</td>\n",
       "      <td>...</td>\n",
       "      <td>1.699483</td>\n",
       "      <td>83.152763</td>\n",
       "      <td>222.761078</td>\n",
       "      <td>40.215744</td>\n",
       "      <td>12.053883</td>\n",
       "      <td>0.443770</td>\n",
       "      <td>5.036349</td>\n",
       "      <td>3.703878</td>\n",
       "      <td>6.479697</td>\n",
       "      <td>67.993462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.307730</td>\n",
       "      <td>0.183246</td>\n",
       "      <td>22.053869</td>\n",
       "      <td>0.265728</td>\n",
       "      <td>145.952515</td>\n",
       "      <td>14.096407</td>\n",
       "      <td>2.054200</td>\n",
       "      <td>2.749843</td>\n",
       "      <td>15.372195</td>\n",
       "      <td>14.193875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065402</td>\n",
       "      <td>14.961164</td>\n",
       "      <td>64.168648</td>\n",
       "      <td>14.070885</td>\n",
       "      <td>1.780867</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>4.729579</td>\n",
       "      <td>0.474927</td>\n",
       "      <td>0.612516</td>\n",
       "      <td>11.067472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.364316</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>73.620064</td>\n",
       "      <td>36.071255</td>\n",
       "      <td>-55.800388</td>\n",
       "      <td>54.802345</td>\n",
       "      <td>-1.355333</td>\n",
       "      <td>61.645058</td>\n",
       "      <td>43.585056</td>\n",
       "      <td>8.474298</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460719</td>\n",
       "      <td>34.275742</td>\n",
       "      <td>-80.985092</td>\n",
       "      <td>0.801388</td>\n",
       "      <td>6.791385</td>\n",
       "      <td>0.238849</td>\n",
       "      <td>-2.576122</td>\n",
       "      <td>1.702451</td>\n",
       "      <td>3.983111</td>\n",
       "      <td>39.285114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.073940</td>\n",
       "      <td>0.584319</td>\n",
       "      <td>104.082581</td>\n",
       "      <td>36.641098</td>\n",
       "      <td>175.959747</td>\n",
       "      <td>74.469139</td>\n",
       "      <td>0.751234</td>\n",
       "      <td>91.832855</td>\n",
       "      <td>73.670395</td>\n",
       "      <td>47.978536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.652951</td>\n",
       "      <td>72.843140</td>\n",
       "      <td>183.248138</td>\n",
       "      <td>30.274240</td>\n",
       "      <td>10.804937</td>\n",
       "      <td>0.410636</td>\n",
       "      <td>2.847863</td>\n",
       "      <td>3.400325</td>\n",
       "      <td>6.089336</td>\n",
       "      <td>59.218407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.804399</td>\n",
       "      <td>0.695298</td>\n",
       "      <td>118.635956</td>\n",
       "      <td>36.734791</td>\n",
       "      <td>238.529449</td>\n",
       "      <td>84.281525</td>\n",
       "      <td>1.439410</td>\n",
       "      <td>93.233742</td>\n",
       "      <td>83.905266</td>\n",
       "      <td>59.766405</td>\n",
       "      <td>...</td>\n",
       "      <td>1.699363</td>\n",
       "      <td>81.219131</td>\n",
       "      <td>217.120224</td>\n",
       "      <td>38.329742</td>\n",
       "      <td>11.866473</td>\n",
       "      <td>0.443224</td>\n",
       "      <td>3.807496</td>\n",
       "      <td>3.738561</td>\n",
       "      <td>6.518030</td>\n",
       "      <td>66.474869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.948053</td>\n",
       "      <td>0.825283</td>\n",
       "      <td>137.710800</td>\n",
       "      <td>36.852093</td>\n",
       "      <td>333.332825</td>\n",
       "      <td>96.065742</td>\n",
       "      <td>2.853918</td>\n",
       "      <td>94.521477</td>\n",
       "      <td>95.448303</td>\n",
       "      <td>68.239954</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746406</td>\n",
       "      <td>91.574539</td>\n",
       "      <td>255.831543</td>\n",
       "      <td>48.442451</td>\n",
       "      <td>13.086332</td>\n",
       "      <td>0.477468</td>\n",
       "      <td>5.330729</td>\n",
       "      <td>4.041468</td>\n",
       "      <td>6.915159</td>\n",
       "      <td>75.622864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.023113</td>\n",
       "      <td>1.650467</td>\n",
       "      <td>211.602493</td>\n",
       "      <td>39.900089</td>\n",
       "      <td>1294.610840</td>\n",
       "      <td>146.211853</td>\n",
       "      <td>16.435431</td>\n",
       "      <td>99.100471</td>\n",
       "      <td>152.501236</td>\n",
       "      <td>93.911957</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921419</td>\n",
       "      <td>174.343643</td>\n",
       "      <td>634.443787</td>\n",
       "      <td>110.932770</td>\n",
       "      <td>22.771687</td>\n",
       "      <td>0.640637</td>\n",
       "      <td>70.544189</td>\n",
       "      <td>5.074804</td>\n",
       "      <td>8.302896</td>\n",
       "      <td>121.379723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               resp  shock_indexes     systolics   temperature         urine  \\\n",
       "count  49960.000000   49961.000000  49987.000000  48611.000000  37130.000000   \n",
       "mean      18.431267       0.714924    122.480316     36.788361    274.272186   \n",
       "std        2.307730       0.183246     22.053869      0.265728    145.952515   \n",
       "min       14.364316       0.214100     73.620064     36.071255    -55.800388   \n",
       "25%       17.073940       0.584319    104.082581     36.641098    175.959747   \n",
       "50%       17.804399       0.695298    118.635956     36.734791    238.529449   \n",
       "75%       18.948053       0.825283    137.710800     36.852093    333.332825   \n",
       "max       45.023113       1.650467    211.602493     39.900089   1294.610840   \n",
       "\n",
       "                MAP    o2_24h_max  spo2_24hr_min         pulse  \\\n",
       "count  49988.000000  49960.000000   49948.000000  49995.000000   \n",
       "mean      86.151390      2.142308      92.862534     85.224884   \n",
       "std       14.096407      2.054200       2.749843     15.372195   \n",
       "min       54.802345     -1.355333      61.645058     43.585056   \n",
       "25%       74.469139      0.751234      91.832855     73.670395   \n",
       "50%       84.281525      1.439410      93.233742     83.905266   \n",
       "75%       96.065742      2.853918      94.521477     95.448303   \n",
       "max      146.211853     16.435431      99.100471    152.501236   \n",
       "\n",
       "       AGE_AT_START_OF_ENCOUNTER  ...        height        weight  \\\n",
       "count               50000.000000  ...  32580.000000  42449.000000   \n",
       "mean                   57.526039  ...      1.699483     83.152763   \n",
       "std                    14.193875  ...      0.065402     14.961164   \n",
       "min                     8.474298  ...      1.460719     34.275742   \n",
       "25%                    47.978536  ...      1.652951     72.843140   \n",
       "50%                    59.766405  ...      1.699363     81.219131   \n",
       "75%                    68.239954  ...      1.746406     91.574539   \n",
       "max                    93.911957  ...      1.921419    174.343643   \n",
       "\n",
       "          platelets  shock_index_age     anion_gap  pulse_pressure  \\\n",
       "count  43742.000000     49953.000000  43573.000000    49979.000000   \n",
       "mean     222.761078        40.215744     12.053883        0.443770   \n",
       "std       64.168648        14.070885      1.780867        0.050794   \n",
       "min      -80.985092         0.801388      6.791385        0.238849   \n",
       "25%      183.248138        30.274240     10.804937        0.410636   \n",
       "50%      217.120224        38.329742     11.866473        0.443224   \n",
       "75%      255.831543        48.442451     13.086332        0.477468   \n",
       "max      634.443787       110.932770     22.771687        0.640637   \n",
       "\n",
       "         window_num       albumin  protein_level    diastolics  \n",
       "count  50000.000000  29704.000000   29355.000000  49986.000000  \n",
       "mean       5.036349      3.703878       6.479697     67.993462  \n",
       "std        4.729579      0.474927       0.612516     11.067472  \n",
       "min       -2.576122      1.702451       3.983111     39.285114  \n",
       "25%        2.847863      3.400325       6.089336     59.218407  \n",
       "50%        3.807496      3.738561       6.518030     66.474869  \n",
       "75%        5.330729      4.041468       6.915159     75.622864  \n",
       "max       70.544189      5.074804       8.302896    121.379723  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_um.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resp                         0.00080\n",
       "shock_indexes                0.00078\n",
       "systolics                    0.00026\n",
       "temperature                  0.02778\n",
       "urine                        0.25740\n",
       "MAP                          0.00024\n",
       "o2_24h_max                   0.00080\n",
       "spo2_24hr_min                0.00104\n",
       "pulse                        0.00010\n",
       "AGE_AT_START_OF_ENCOUNTER    0.00000\n",
       "bun                          0.13058\n",
       "calcium                      0.12912\n",
       "chloride                     0.12788\n",
       "co2                          0.12976\n",
       "creatinine                   0.12732\n",
       "glucose                      0.09140\n",
       "hematocrit                   0.11732\n",
       "hemoglobin                   0.12062\n",
       "mean_corps_hgb               0.12254\n",
       "mean_corps_hgb_conc          0.12288\n",
       "mean_corps_hgb_vol           0.12364\n",
       "mean_platelet_vol            0.13586\n",
       "potassium                    0.11558\n",
       "red_blood_cell_count         0.12384\n",
       "red_cell_dist_width          0.12604\n",
       "sodium                       0.11644\n",
       "gcs                          0.22154\n",
       "white_blood_cell_count       0.12524\n",
       "bilirubin                    0.41636\n",
       "magnesium                    0.51172\n",
       "phosphorus                   0.59054\n",
       "lactate                      0.66016\n",
       "INR                          0.50196\n",
       "PTT                          0.58834\n",
       "PT_Seconds                   0.50672\n",
       "height                       0.34840\n",
       "weight                       0.15102\n",
       "platelets                    0.12516\n",
       "shock_index_age              0.00094\n",
       "anion_gap                    0.12854\n",
       "pulse_pressure               0.00042\n",
       "window_num                   0.00000\n",
       "albumin                      0.40592\n",
       "protein_level                0.41290\n",
       "diastolics                   0.00028\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_um.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and Impute with mean\n",
    "* Better imputation methods could be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaler = SimulationDataScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<simulator.SimulationDataScaler at 0x7fe4bf2effd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaler.fit(X_train_um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_um_scaled, X_train_um_ind = data_scaler.transform(X_train_um)\n",
    "X_val_um_scaled, X_val_um_ind = data_scaler.transform(X_val_um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp</th>\n",
       "      <th>shock_indexes</th>\n",
       "      <th>systolics</th>\n",
       "      <th>temperature</th>\n",
       "      <th>urine</th>\n",
       "      <th>MAP</th>\n",
       "      <th>o2_24h_max</th>\n",
       "      <th>spo2_24hr_min</th>\n",
       "      <th>pulse</th>\n",
       "      <th>AGE_AT_START_OF_ENCOUNTER</th>\n",
       "      <th>...</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>platelets</th>\n",
       "      <th>shock_index_age</th>\n",
       "      <th>anion_gap</th>\n",
       "      <th>pulse_pressure</th>\n",
       "      <th>window_num</th>\n",
       "      <th>albumin</th>\n",
       "      <th>protein_level</th>\n",
       "      <th>diastolics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.324219e-09</td>\n",
       "      <td>2.441406e-09</td>\n",
       "      <td>1.052856e-08</td>\n",
       "      <td>7.324219e-09</td>\n",
       "      <td>1.220703e-09</td>\n",
       "      <td>1.007080e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.441406e-09</td>\n",
       "      <td>1.586914e-08</td>\n",
       "      <td>-1.220703e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.098633e-08</td>\n",
       "      <td>7.629395e-09</td>\n",
       "      <td>1.098633e-08</td>\n",
       "      <td>7.324219e-09</td>\n",
       "      <td>-9.765625e-09</td>\n",
       "      <td>1.039505e-08</td>\n",
       "      <td>-3.662109e-09</td>\n",
       "      <td>-4.882812e-09</td>\n",
       "      <td>1.342773e-08</td>\n",
       "      <td>-8.544922e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.996099e-01</td>\n",
       "      <td>9.996199e-01</td>\n",
       "      <td>9.998800e-01</td>\n",
       "      <td>9.860221e-01</td>\n",
       "      <td>8.617510e-01</td>\n",
       "      <td>9.998900e-01</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>9.994898e-01</td>\n",
       "      <td>9.999600e-01</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.072255e-01</td>\n",
       "      <td>9.214103e-01</td>\n",
       "      <td>9.353381e-01</td>\n",
       "      <td>9.995399e-01</td>\n",
       "      <td>9.335296e-01</td>\n",
       "      <td>9.998000e-01</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>7.707736e-01</td>\n",
       "      <td>7.662322e-01</td>\n",
       "      <td>9.998700e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.762334e+00</td>\n",
       "      <td>-2.733105e+00</td>\n",
       "      <td>-2.215518e+00</td>\n",
       "      <td>-2.698680e+00</td>\n",
       "      <td>-2.261537e+00</td>\n",
       "      <td>-2.223925e+00</td>\n",
       "      <td>-1.702695</td>\n",
       "      <td>-1.135257e+01</td>\n",
       "      <td>-2.708803e+00</td>\n",
       "      <td>-3.455873e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.650757e+00</td>\n",
       "      <td>-3.266965e+00</td>\n",
       "      <td>-4.733614e+00</td>\n",
       "      <td>-2.801157e+00</td>\n",
       "      <td>-2.955055e+00</td>\n",
       "      <td>-4.034411e+00</td>\n",
       "      <td>-1.609561e+00</td>\n",
       "      <td>-4.214249e+00</td>\n",
       "      <td>-4.076025e+00</td>\n",
       "      <td>-2.593966e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.879122e-01</td>\n",
       "      <td>-7.120336e-01</td>\n",
       "      <td>-8.339903e-01</td>\n",
       "      <td>-5.443461e-01</td>\n",
       "      <td>-5.286755e-01</td>\n",
       "      <td>-8.286207e-01</td>\n",
       "      <td>-0.676989</td>\n",
       "      <td>-3.735618e-01</td>\n",
       "      <td>-7.516282e-01</td>\n",
       "      <td>-6.726560e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.148487e-01</td>\n",
       "      <td>-5.847651e-01</td>\n",
       "      <td>-5.317143e-01</td>\n",
       "      <td>-7.057414e-01</td>\n",
       "      <td>-6.054935e-01</td>\n",
       "      <td>-6.520727e-01</td>\n",
       "      <td>-4.627278e-01</td>\n",
       "      <td>-1.247874e-01</td>\n",
       "      <td>-1.297121e-01</td>\n",
       "      <td>-7.927659e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.711526e-01</td>\n",
       "      <td>-1.060090e-01</td>\n",
       "      <td>-1.733065e-01</td>\n",
       "      <td>-1.815041e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.321312e-01</td>\n",
       "      <td>-0.341537</td>\n",
       "      <td>1.339325e-01</td>\n",
       "      <td>-8.573830e-02</td>\n",
       "      <td>1.578422e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.327677e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.032614e-02</td>\n",
       "      <td>-2.598256e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.367543e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.236488e-01</td>\n",
       "      <td>6.012142e-01</td>\n",
       "      <td>6.903922e-01</td>\n",
       "      <td>2.214300e-01</td>\n",
       "      <td>1.249265e-01</td>\n",
       "      <td>7.031777e-01</td>\n",
       "      <td>0.345502</td>\n",
       "      <td>6.026543e-01</td>\n",
       "      <td>6.649721e-01</td>\n",
       "      <td>7.548344e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.231322e-01</td>\n",
       "      <td>4.098270e-01</td>\n",
       "      <td>4.051115e-01</td>\n",
       "      <td>5.836623e-01</td>\n",
       "      <td>4.573106e-01</td>\n",
       "      <td>6.631775e-01</td>\n",
       "      <td>6.224296e-02</td>\n",
       "      <td>2.687464e-01</td>\n",
       "      <td>2.535732e-01</td>\n",
       "      <td>6.891508e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.152306e+01</td>\n",
       "      <td>5.105456e+00</td>\n",
       "      <td>4.041153e+00</td>\n",
       "      <td>1.171029e+01</td>\n",
       "      <td>6.990989e+00</td>\n",
       "      <td>4.260736e+00</td>\n",
       "      <td>6.958070</td>\n",
       "      <td>2.268493e+00</td>\n",
       "      <td>4.376540e+00</td>\n",
       "      <td>2.563520e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.393467e+00</td>\n",
       "      <td>6.095245e+00</td>\n",
       "      <td>6.415709e+00</td>\n",
       "      <td>5.025820e+00</td>\n",
       "      <td>6.018375e+00</td>\n",
       "      <td>3.875848e+00</td>\n",
       "      <td>1.385081e+01</td>\n",
       "      <td>2.886654e+00</td>\n",
       "      <td>2.976625e+00</td>\n",
       "      <td>4.823757e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               resp  shock_indexes     systolics   temperature         urine  \\\n",
       "count  5.000000e+04   5.000000e+04  5.000000e+04  5.000000e+04  5.000000e+04   \n",
       "mean   7.324219e-09   2.441406e-09  1.052856e-08  7.324219e-09  1.220703e-09   \n",
       "std    9.996099e-01   9.996199e-01  9.998800e-01  9.860221e-01  8.617510e-01   \n",
       "min   -1.762334e+00  -2.733105e+00 -2.215518e+00 -2.698680e+00 -2.261537e+00   \n",
       "25%   -5.879122e-01  -7.120336e-01 -8.339903e-01 -5.443461e-01 -5.286755e-01   \n",
       "50%   -2.711526e-01  -1.060090e-01 -1.733065e-01 -1.815041e-01  0.000000e+00   \n",
       "75%    2.236488e-01   6.012142e-01  6.903922e-01  2.214300e-01  1.249265e-01   \n",
       "max    1.152306e+01   5.105456e+00  4.041153e+00  1.171029e+01  6.990989e+00   \n",
       "\n",
       "                MAP    o2_24h_max  spo2_24hr_min         pulse  \\\n",
       "count  5.000000e+04  50000.000000   5.000000e+04  5.000000e+04   \n",
       "mean   1.007080e-08      0.000000   2.441406e-09  1.586914e-08   \n",
       "std    9.998900e-01      0.999610   9.994898e-01  9.999600e-01   \n",
       "min   -2.223925e+00     -1.702695  -1.135257e+01 -2.708803e+00   \n",
       "25%   -8.286207e-01     -0.676989  -3.735618e-01 -7.516282e-01   \n",
       "50%   -1.321312e-01     -0.341537   1.339325e-01 -8.573830e-02   \n",
       "75%    7.031777e-01      0.345502   6.026543e-01  6.649721e-01   \n",
       "max    4.260736e+00      6.958070   2.268493e+00  4.376540e+00   \n",
       "\n",
       "       AGE_AT_START_OF_ENCOUNTER  ...        height        weight  \\\n",
       "count               5.000000e+04  ...  5.000000e+04  5.000000e+04   \n",
       "mean               -1.220703e-08  ... -1.098633e-08  7.629395e-09   \n",
       "std                 1.000010e+00  ...  8.072255e-01  9.214103e-01   \n",
       "min                -3.455873e+00  ... -3.650757e+00 -3.266965e+00   \n",
       "25%                -6.726560e-01  ... -3.148487e-01 -5.847651e-01   \n",
       "50%                 1.578422e-01  ...  0.000000e+00  0.000000e+00   \n",
       "75%                 7.548344e-01  ...  3.231322e-01  4.098270e-01   \n",
       "max                 2.563520e+00  ...  3.393467e+00  6.095245e+00   \n",
       "\n",
       "          platelets  shock_index_age     anion_gap  pulse_pressure  \\\n",
       "count  5.000000e+04     5.000000e+04  5.000000e+04    5.000000e+04   \n",
       "mean   1.098633e-08     7.324219e-09 -9.765625e-09    1.039505e-08   \n",
       "std    9.353381e-01     9.995399e-01  9.335296e-01    9.998000e-01   \n",
       "min   -4.733614e+00    -2.801157e+00 -2.955055e+00   -4.034411e+00   \n",
       "25%   -5.317143e-01    -7.057414e-01 -6.054935e-01   -6.520727e-01   \n",
       "50%    0.000000e+00    -1.327677e-01  0.000000e+00   -1.032614e-02   \n",
       "75%    4.051115e-01     5.836623e-01  4.573106e-01    6.631775e-01   \n",
       "max    6.415709e+00     5.025820e+00  6.018375e+00    3.875848e+00   \n",
       "\n",
       "         window_num       albumin  protein_level    diastolics  \n",
       "count  5.000000e+04  5.000000e+04   5.000000e+04  5.000000e+04  \n",
       "mean  -3.662109e-09 -4.882812e-09   1.342773e-08 -8.544922e-09  \n",
       "std    1.000010e+00  7.707736e-01   7.662322e-01  9.998700e-01  \n",
       "min   -1.609561e+00 -4.214249e+00  -4.076025e+00 -2.593966e+00  \n",
       "25%   -4.627278e-01 -1.247874e-01  -1.297121e-01 -7.927659e-01  \n",
       "50%   -2.598256e-01  0.000000e+00   0.000000e+00 -1.367543e-01  \n",
       "75%    6.224296e-02  2.687464e-01   2.535732e-01  6.891508e-01  \n",
       "max    1.385081e+01  2.886654e+00   2.976625e+00  4.823757e+00  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_um_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features_with_y = X_train_um_scaled.shape[1] + 1 # add 1 for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(input_features=input_features_with_y, codings_size=16, d1_size=256, d2_size=128, d3_size=64, d4_size=32, patience=7, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.8927 - numeric_loss: 0.7158 - categorical_loss: 0.1789 - val_loss: 0.6902 - val_numeric_loss: 0.5318 - val_categorical_loss: 0.0749\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6858 - numeric_loss: 0.5042 - categorical_loss: 0.0548 - val_loss: 0.6226 - val_numeric_loss: 0.4482 - val_categorical_loss: 0.0587\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6391 - numeric_loss: 0.4485 - categorical_loss: 0.0522 - val_loss: 0.5859 - val_numeric_loss: 0.4071 - val_categorical_loss: 0.0553\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6092 - numeric_loss: 0.4153 - categorical_loss: 0.0503 - val_loss: 0.5605 - val_numeric_loss: 0.3762 - val_categorical_loss: 0.0474\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5904 - numeric_loss: 0.3954 - categorical_loss: 0.0420 - val_loss: 0.5440 - val_numeric_loss: 0.3572 - val_categorical_loss: 0.0381\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5765 - numeric_loss: 0.3772 - categorical_loss: 0.0404 - val_loss: 0.5309 - val_numeric_loss: 0.3395 - val_categorical_loss: 0.0360\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5638 - numeric_loss: 0.3619 - categorical_loss: 0.0377 - val_loss: 0.5185 - val_numeric_loss: 0.3276 - val_categorical_loss: 0.0371\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5572 - numeric_loss: 0.3516 - categorical_loss: 0.0405 - val_loss: 0.5090 - val_numeric_loss: 0.3126 - val_categorical_loss: 0.0357\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5481 - numeric_loss: 0.3409 - categorical_loss: 0.0398 - val_loss: 0.5012 - val_numeric_loss: 0.3047 - val_categorical_loss: 0.0351\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5405 - numeric_loss: 0.3324 - categorical_loss: 0.0382 - val_loss: 0.4974 - val_numeric_loss: 0.3014 - val_categorical_loss: 0.0305\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5369 - numeric_loss: 0.3277 - categorical_loss: 0.0374 - val_loss: 0.4931 - val_numeric_loss: 0.2893 - val_categorical_loss: 0.0327\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5295 - numeric_loss: 0.3199 - categorical_loss: 0.0370 - val_loss: 0.4860 - val_numeric_loss: 0.2904 - val_categorical_loss: 0.0274\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5278 - numeric_loss: 0.3168 - categorical_loss: 0.0377 - val_loss: 0.4819 - val_numeric_loss: 0.2761 - val_categorical_loss: 0.0326\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5250 - numeric_loss: 0.3121 - categorical_loss: 0.0411 - val_loss: 0.4784 - val_numeric_loss: 0.2783 - val_categorical_loss: 0.0346\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5215 - numeric_loss: 0.3098 - categorical_loss: 0.0370 - val_loss: 0.4759 - val_numeric_loss: 0.2759 - val_categorical_loss: 0.0325\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5188 - numeric_loss: 0.3066 - categorical_loss: 0.0363 - val_loss: 0.4771 - val_numeric_loss: 0.2739 - val_categorical_loss: 0.0326\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5191 - numeric_loss: 0.3056 - categorical_loss: 0.0369 - val_loss: 0.4709 - val_numeric_loss: 0.2688 - val_categorical_loss: 0.0264\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5146 - numeric_loss: 0.3020 - categorical_loss: 0.0363 - val_loss: 0.4714 - val_numeric_loss: 0.2687 - val_categorical_loss: 0.0291\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5138 - numeric_loss: 0.3000 - categorical_loss: 0.0372 - val_loss: 0.4697 - val_numeric_loss: 0.2678 - val_categorical_loss: 0.0280\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5115 - numeric_loss: 0.2982 - categorical_loss: 0.0368 - val_loss: 0.4680 - val_numeric_loss: 0.2641 - val_categorical_loss: 0.0288\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5120 - numeric_loss: 0.2980 - categorical_loss: 0.0382 - val_loss: 0.4669 - val_numeric_loss: 0.2630 - val_categorical_loss: 0.0299\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5091 - numeric_loss: 0.2954 - categorical_loss: 0.0350 - val_loss: 0.4655 - val_numeric_loss: 0.2626 - val_categorical_loss: 0.0271\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5080 - numeric_loss: 0.2943 - categorical_loss: 0.0343 - val_loss: 0.4640 - val_numeric_loss: 0.2592 - val_categorical_loss: 0.0319\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5070 - numeric_loss: 0.2919 - categorical_loss: 0.0352 - val_loss: 0.4627 - val_numeric_loss: 0.2541 - val_categorical_loss: 0.0276\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5076 - numeric_loss: 0.2909 - categorical_loss: 0.0369 - val_loss: 0.4615 - val_numeric_loss: 0.2553 - val_categorical_loss: 0.0295\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5053 - numeric_loss: 0.2885 - categorical_loss: 0.0374 - val_loss: 0.4611 - val_numeric_loss: 0.2504 - val_categorical_loss: 0.0316\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5028 - numeric_loss: 0.2854 - categorical_loss: 0.0357 - val_loss: 0.4604 - val_numeric_loss: 0.2528 - val_categorical_loss: 0.0285\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5045 - numeric_loss: 0.2862 - categorical_loss: 0.0364 - val_loss: 0.4590 - val_numeric_loss: 0.2521 - val_categorical_loss: 0.0287\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5028 - numeric_loss: 0.2842 - categorical_loss: 0.0369 - val_loss: 0.4576 - val_numeric_loss: 0.2514 - val_categorical_loss: 0.0291\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5007 - numeric_loss: 0.2829 - categorical_loss: 0.0337 - val_loss: 0.4568 - val_numeric_loss: 0.2497 - val_categorical_loss: 0.0241\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5001 - numeric_loss: 0.2818 - categorical_loss: 0.0371 - val_loss: 0.4567 - val_numeric_loss: 0.2449 - val_categorical_loss: 0.0350\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4981 - numeric_loss: 0.2796 - categorical_loss: 0.0352 - val_loss: 0.4560 - val_numeric_loss: 0.2515 - val_categorical_loss: 0.0237\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4991 - numeric_loss: 0.2807 - categorical_loss: 0.0351 - val_loss: 0.4577 - val_numeric_loss: 0.2480 - val_categorical_loss: 0.0261\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4990 - numeric_loss: 0.2802 - categorical_loss: 0.0364 - val_loss: 0.4539 - val_numeric_loss: 0.2470 - val_categorical_loss: 0.0278\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4972 - numeric_loss: 0.2789 - categorical_loss: 0.0342 - val_loss: 0.4530 - val_numeric_loss: 0.2436 - val_categorical_loss: 0.0276\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4971 - numeric_loss: 0.2788 - categorical_loss: 0.0343 - val_loss: 0.4555 - val_numeric_loss: 0.2479 - val_categorical_loss: 0.0302\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4964 - numeric_loss: 0.2782 - categorical_loss: 0.0320 - val_loss: 0.4547 - val_numeric_loss: 0.2470 - val_categorical_loss: 0.0248\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4973 - numeric_loss: 0.2781 - categorical_loss: 0.0354 - val_loss: 0.4536 - val_numeric_loss: 0.2431 - val_categorical_loss: 0.0233\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4960 - numeric_loss: 0.2769 - categorical_loss: 0.0344 - val_loss: 0.4511 - val_numeric_loss: 0.2444 - val_categorical_loss: 0.0225\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4932 - numeric_loss: 0.2754 - categorical_loss: 0.0320 - val_loss: 0.4541 - val_numeric_loss: 0.2455 - val_categorical_loss: 0.0225\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4951 - numeric_loss: 0.2761 - categorical_loss: 0.0339 - val_loss: 0.4502 - val_numeric_loss: 0.2450 - val_categorical_loss: 0.0230\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4950 - numeric_loss: 0.2762 - categorical_loss: 0.0332 - val_loss: 0.4504 - val_numeric_loss: 0.2388 - val_categorical_loss: 0.0242\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4930 - numeric_loss: 0.2743 - categorical_loss: 0.0332 - val_loss: 0.4472 - val_numeric_loss: 0.2374 - val_categorical_loss: 0.0225\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4923 - numeric_loss: 0.2743 - categorical_loss: 0.0322 - val_loss: 0.4504 - val_numeric_loss: 0.2434 - val_categorical_loss: 0.0208\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4933 - numeric_loss: 0.2739 - categorical_loss: 0.0363 - val_loss: 0.4485 - val_numeric_loss: 0.2430 - val_categorical_loss: 0.0225\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4925 - numeric_loss: 0.2735 - categorical_loss: 0.0337 - val_loss: 0.4485 - val_numeric_loss: 0.2398 - val_categorical_loss: 0.0227\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4924 - numeric_loss: 0.2740 - categorical_loss: 0.0334 - val_loss: 0.4474 - val_numeric_loss: 0.2405 - val_categorical_loss: 0.0198\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4922 - numeric_loss: 0.2733 - categorical_loss: 0.0330 - val_loss: 0.4478 - val_numeric_loss: 0.2394 - val_categorical_loss: 0.0256\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4916 - numeric_loss: 0.2726 - categorical_loss: 0.0352 - val_loss: 0.4503 - val_numeric_loss: 0.2416 - val_categorical_loss: 0.0231\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4918 - numeric_loss: 0.2732 - categorical_loss: 0.0332 - val_loss: 0.4499 - val_numeric_loss: 0.2419 - val_categorical_loss: 0.0203\n"
     ]
    }
   ],
   "source": [
    "history = vae.fit(X_train_um_scaled,Y_train_um,X_val_um_scaled,Y_val_um\n",
    "                  ,batch_size=512, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Y to X matrix for evaluation\n",
    "\n",
    "X_val_um_scaled_with_y = X_val_um_scaled.copy()\n",
    "X_val_um_scaled_with_y['Target'] = Y_val_um\n",
    "\n",
    "X_val_um_with_y = X_val_um.copy()\n",
    "X_val_um_with_y['Target'] = Y_val_um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, codings_val = vae.predict_encoder(X_val_um_scaled,Y_val_um)\n",
    "X_val_with_y_pred = vae.predict_decoder(codings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_pred = pd.DataFrame(X_val_with_y_pred).corr()\n",
    "corr_mat_imp = pd.DataFrame(X_val_um_scaled_with_y).corr()\n",
    "corr_mat_raw = pd.DataFrame(X_val_um_with_y).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967391304347826"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sign(np.triu(corr_mat_pred)) == np.sign(np.triu(corr_mat_raw))).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The signs of the upper triangle of the correlation matricies match very well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_um_with_y_df = pd.DataFrame(X_val_um_with_y)\n",
    "X_val_with_y_pred_df = pd.DataFrame(X_val_with_y_pred)\n",
    "\n",
    "loss1_cors = []\n",
    "for i in range(0,X_val_um_with_y_df.shape[1]):\n",
    "    use = X_val_um_with_y_df.iloc[:,i].notna().values\n",
    "    r,p = pearsonr( X_val_um_with_y_df.loc[use].iloc[:,i].values,\n",
    "                   X_val_with_y_pred_df.loc[use].iloc[:,i].values )\n",
    "    loss1_cors.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8751452669550324"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(loss1_cors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The average Pearson correlation between the reconstructions and the raw variables is strong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_model = 'example_model.h5'\n",
    "vae.save(out_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 cgillies 4294967294 476K Jan 20 16:51 example_model.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh $out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
